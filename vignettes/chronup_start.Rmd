---
title: "Chronological Uncertainty Propagation Toolkit"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{chronup_start}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Chronological uncertainty is a ubiquitous challenge for sciences of the past. Nearly all of the observations we can make about past people, animals, plants, objects, and events need to be dated, and those dates are usually uncertain. The dates are uncertain because all of the chronometric methods available to us come with uncertainty. Some methods come with relatively small uncertainties, like dendrochronology, which can yield age estimates with single-year errors. Others come with much higher levels of uncertainty, like radiocarbon dating, which can yield age estimates with errors ranging from decades to centuries or more. For a long time, these uncertainties have been acknowledged by the scientific community but are usually left out of formal analyses. As a result, many studies of the past contain a hidden bias, caused by a failure to incorporate the chronological uncertainty we know accompanies observations about the past. Recently, some effort has been directed toward understanding the impact that this neglect has on quantitative methods commonly used in fields like archaeology and palaeoclimatology and, consequently, the impact it has on our current understanding of the past. At the same time, statistical approaches with better handling of chronological uncertainty are being developed. One methodological avenue actively being explored involves uncertainty (error) propagation, and the R package chronup is being developed to provide access to the statistical tools produced as part of that ongoing research.

```{r setup}
library(chronup)
```

To begin, simulate some data:

```{r}
nintervals <- 1000
times <- 5000:4001
beta <- -0.004
process <- exp(1:nintervals * beta)
nevents <- 10
nsamples <- 1000
sim_sequences <- simulate_event_counts(process = process,
                            times = times,
                            nevents = nevents,
                            nsamples = nsamples,
                            bigmatrix = T,
                            parallel = F)

Y <- bigmemory::attach.big.matrix(sim_sequences$Y)
n <- dim(Y)[1]
x <- cbind(rep(1, n),1:n)

bigmemory::filebacked.big.matrix(nrow = n,
                                ncol = nsamples * dim(x)[2],
                                backingfile = "X_mat",
                                backingpath = getwd(),
                                descriptorfile = "X_desc")

big_matrix_path <- paste(getwd(),"X_desc",sep="/")

chronup:::rep_big_x(x,
                nsamples,
                big_matrix_path,
                parallel = F)

X <- bigmemory::attach.big.matrix(paste(getwd(),"X_desc",sep="/"))
```

Then, call the mcmc:

```{r}
startvals <- c(0,0)
startscales <- c(0.1, 0.0002)

mcmc_samples_adapt <- regress(Y = Y,
                            X = X,
                            model = "pois",
                            startvals = startvals,
                            scales = startscales,
                            adapt = F)
```
